{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here grab dataset from folder\n",
    "batch_size = 50\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "ushapes = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_supervised/square_images_size224_cleaned/UShape/\"\n",
    "no_ushapes = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_supervised/square_images_size224_cleaned/NoUShape/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total specto: 3990, ushape: 168, noushape: 3822\n",
      "training size: 39, testing size: 997, unlabeled size: 2952\n"
     ]
    }
   ],
   "source": [
    "def extract_spectrograms(path):\n",
    "  os.chdir(path)\n",
    "  spectrograms = []\n",
    "\n",
    "  with os.scandir(path) as files:\n",
    "    for file in files:\n",
    "      if file.name.endswith('.png'):\n",
    "        spectrograms.append(file.path)\n",
    "  return spectrograms\n",
    "\n",
    "ushapes_spectrograms = extract_spectrograms(ushapes)\n",
    "no_ushape_spectrograms = extract_spectrograms(no_ushapes)\n",
    "total_spectograms = ushapes_spectrograms + no_ushape_spectrograms\n",
    "print(f\"total specto: {len(total_spectograms)}, ushape: {len(ushapes_spectrograms)}, noushape: {len(no_ushape_spectrograms)}\")\n",
    "training_size = int(len(total_spectograms) * 0.01)\n",
    "testing_size = int(len(total_spectograms) * 0.25)\n",
    "unlabeled_size = int(len(total_spectograms) * .74)\n",
    "print(f\"training size: {training_size}, testing size: {testing_size}, unlabeled size: {unlabeled_size}\")\n",
    "\n",
    "import random\n",
    "random.shuffle(total_spectograms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_supervised_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/\"\n",
    "# train_ushape_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/train/ushape/\"\n",
    "# train_noushape_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/train/noushape/\"\n",
    "# test_ushape_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/test/ushape/\"\n",
    "# test_noushape_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/test/noushape/\"\n",
    "# unlabeled_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/unlabeled/\"\n",
    "# # for i, ushape in enumerate(os.listdir(ushapes)):\n",
    "# #     print(i, ushape)\n",
    "# third_ushape = 168/3\n",
    "# third_noushape = 3822/3\n",
    "\n",
    "# #splitting ushape\n",
    "\n",
    "# for i, ushape in enumerate(os.listdir(ushapes)):\n",
    "#     if(ushape.endswith('png')):\n",
    "#         if i<third_ushape:\n",
    "#             shutil.copy(ushapes + ushape, train_ushape_path + ushape)\n",
    "#         elif i>third_ushape and i<third_ushape*2:\n",
    "#             shutil.copy(ushapes + ushape, test_ushape_path + ushape)\n",
    "#         elif i>third_ushape*2:\n",
    "#             shutil.copy(ushapes + ushape, unlabeled_path + ushape)\n",
    "# #spltting noushape\n",
    "# for i, noushape in enumerate(os.listdir(no_ushapes)):\n",
    "#     if(noushape.endswith('png')):\n",
    "#         if i<third_noushape:\n",
    "#             shutil.copy(no_ushapes + noushape, train_noushape_path + noushape)\n",
    "#         elif i>third_noushape and i<third_noushape*2:\n",
    "#             shutil.copy(no_ushapes + noushape, test_noushape_path + noushape)\n",
    "#         elif i>third_noushape*2:\n",
    "#             shutil.copy(no_ushapes + noushape, unlabeled_path + noushape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_df_with_label(spectrograms, label):\n",
    "  new_df =  pd.DataFrame()\n",
    "  new_df['filename'] = spectrograms\n",
    "  new_df['label'] = [label] * len(spectrograms)\n",
    "\n",
    "  return new_df\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ImageDataGenerator object\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ") \n",
    "\n",
    "#TODO edit parameters after changing lists to be dataframes\n",
    "# Generate batches and augment the images\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    # directory='harp/training/',\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    # directory='harp/validation/',\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
