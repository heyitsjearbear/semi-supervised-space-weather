{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jereb\\anaconda3\\envs\\tensor\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\jereb\\anaconda3\\envs\\tensor\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\jereb\\anaconda3\\envs\\tensor\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here grab dataset from folder\n",
    "batch_size = 50\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "ushapes = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_supervised/square_images_size224_cleaned/UShape/\"\n",
    "no_ushapes = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_supervised/square_images_size224_cleaned/NoUShape/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total specto: 3990, ushape: 168, noushape: 3822\n",
      "training size: 39, testing size: 997, unlabeled size: 2952\n"
     ]
    }
   ],
   "source": [
    "def extract_spectrograms(path):\n",
    "  os.chdir(path)\n",
    "  spectrograms = []\n",
    "\n",
    "  with os.scandir(path) as files:\n",
    "    for file in files:\n",
    "      if file.name.endswith('.png'):\n",
    "        spectrograms.append(file.path)\n",
    "  return spectrograms\n",
    "\n",
    "ushapes_spectrograms = extract_spectrograms(ushapes)\n",
    "no_ushape_spectrograms = extract_spectrograms(no_ushapes)\n",
    "total_spectograms = ushapes_spectrograms + no_ushape_spectrograms\n",
    "print(f\"total specto: {len(total_spectograms)}, ushape: {len(ushapes_spectrograms)}, noushape: {len(no_ushape_spectrograms)}\")\n",
    "training_size = int(len(total_spectograms) * 0.01)\n",
    "testing_size = int(len(total_spectograms) * 0.25)\n",
    "unlabeled_size = int(len(total_spectograms) * .74)\n",
    "print(f\"training size: {training_size}, testing size: {testing_size}, unlabeled size: {unlabeled_size}\")\n",
    "\n",
    "import random\n",
    "random.shuffle(total_spectograms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_supervised_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/\"\n",
    "train_ushape_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/train/ushape/\"\n",
    "train_noushape_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/train/noushape/\"\n",
    "test_ushape_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/test/ushape/\"\n",
    "test_noushape_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/test/noushape/\"\n",
    "unlabeled_path = r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/unlabeled/\"\n",
    "#clear folders just in case\n",
    "if len(os.listdir(train_ushape_path))!=0:\n",
    "    for f in os.listdir(train_ushape_path):\n",
    "        os.remove(train_ushape_path+f)\n",
    "if len(os.listdir(train_noushape_path))!=0:\n",
    "    for f in os.listdir(train_noushape_path):\n",
    "        os.remove(train_noushape_path + f)\n",
    "if len(os.listdir(test_ushape_path))!=0:\n",
    "    for f in os.listdir(test_ushape_path):\n",
    "        os.remove(test_ushape_path+f)\n",
    "if len(os.listdir(test_noushape_path))!=0:\n",
    "    for f in os.listdir(test_noushape_path):\n",
    "        os.remove(test_noushape_path+f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_ushape = 168/3 * 0.01\n",
    "third_noushape = 3822/3 * 0.25\n",
    "#splitting ushape\n",
    "\n",
    "for i, ushape in enumerate(os.listdir(ushapes)):\n",
    "    if(ushape.endswith('png')):\n",
    "        if i<third_ushape:\n",
    "            shutil.copy(ushapes + ushape, train_ushape_path + ushape)\n",
    "        elif i>third_ushape and i<third_ushape*2:\n",
    "            shutil.copy(ushapes + ushape, test_ushape_path + ushape)\n",
    "        elif i>third_ushape*2:\n",
    "            shutil.copy(ushapes + ushape, unlabeled_path + ushape)\n",
    "#spltting noushape\n",
    "for i, noushape in enumerate(os.listdir(no_ushapes)):\n",
    "    if(noushape.endswith('png')):\n",
    "        if i<third_noushape:\n",
    "            shutil.copy(no_ushapes + noushape, train_noushape_path + noushape)\n",
    "        elif i>third_noushape and i<third_noushape*2:\n",
    "            shutil.copy(no_ushapes + noushape, test_noushape_path + noushape)\n",
    "        elif i>third_noushape*2:\n",
    "            shutil.copy(no_ushapes + noushape, unlabeled_path + noushape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training = 311\n",
      "size of testing = 319\n",
      "size of unlabeled = 3359\n"
     ]
    }
   ],
   "source": [
    "print(f\"size of training = {len(os.listdir(train_ushape_path))+len(os.listdir(train_noushape_path))}\")\n",
    "print(f\"size of testing = {len(os.listdir(test_ushape_path))+len(os.listdir(test_noushape_path))}\")\n",
    "print(f\"size of unlabeled = {len(os.listdir(unlabeled_path))-4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     os.makedirs(f'{unlabeled_path}fold_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_0 = unlabeled_path + r\"fold_0/\"\n",
    "fold_1 = unlabeled_path + r\"fold_1/\"\n",
    "fold_2 = unlabeled_path + r\"fold_2/\"\n",
    "fold_3 = unlabeled_path + r\"fold_3/\"\n",
    "#clear fold folders just in case\n",
    "if len(os.listdir(fold_0))!=0:\n",
    "    for f in os.listdir(fold_0):\n",
    "        os.remove(fold_0+f)\n",
    "if len(os.listdir(fold_1))!=0:\n",
    "    for f in os.listdir(fold_1):\n",
    "        os.remove(fold_1 + f)\n",
    "if len(os.listdir(fold_2))!=0:\n",
    "    for f in os.listdir(fold_2):\n",
    "        os.remove(fold_2+f)\n",
    "if len(os.listdir(fold_3))!=0:\n",
    "    for f in os.listdir(fold_3):\n",
    "        os.remove(fold_3+f)\n",
    "fold_length = 3359/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split unlabeled between folds\n",
    "for i, unlabeled in enumerate(os.listdir(unlabeled_path)):\n",
    "    if(unlabeled.endswith('png')):\n",
    "        if i<fold_length:\n",
    "            shutil.move(unlabeled_path + unlabeled, fold_0 + unlabeled)\n",
    "        elif i>fold_length and i<fold_length*2:\n",
    "            shutil.move(unlabeled_path + unlabeled, fold_1 + unlabeled)\n",
    "        elif i>fold_length*2 and i<fold_length*3:\n",
    "            shutil.move(unlabeled_path + unlabeled, fold_2 + unlabeled)\n",
    "        elif(i>fold_length*3):\n",
    "            shutil.move(unlabeled_path + unlabeled, fold_3 + unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ImageDataGenerator object\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ") \n",
    "\n",
    "#TODO edit parameters after changing lists to be dataframes\n",
    "# Generate batches and augment the images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/train\",\n",
    "    # directory='harp/training/',\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:/Users/jereb/Downloads/harp_dataset/HARP_DATASET/dataset_semisupervised/test\",\n",
    "    # directory='harp/validation/',\n",
    "    class_mode='binary',\n",
    "    target_size=(224, 224),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(METRICS):\n",
    "  model = Sequential([\n",
    "    #data_augmentation,\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "model = create_model(METRICS)\n",
    "history = model.fit_generator(generator=\n",
    "  train_generator,\n",
    "  validation_data=val_generator,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
